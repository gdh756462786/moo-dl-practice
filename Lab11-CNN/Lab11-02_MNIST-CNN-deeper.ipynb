{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../data/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"../data/MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reshape needed for CNN\n",
    "# gray image(1-channel) with size 28 x 28\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# L1 ImgIn shape=(?, 28, 28, 1)\n",
    "W1 = tf.Variable(tf.truncated_normal([3, 3, 1, 32], stddev=0.01))\n",
    "#    Conv     -> (?, 28, 28, 32)\n",
    "L1 = tf.nn.conv2d(X_img, filter=W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L1 = tf.nn.relu(L1)\n",
    "#    Pool     -> (?, 14, 14, 32)\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "L1 = tf.nn.dropout(L1, keep_prob=keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# L2 ImgIn shape=(?, 14, 14, 32)\n",
    "W2 = tf.Variable(tf.truncated_normal([3, 3, 32, 64], stddev=0.01))\n",
    "#    Conv      ->(?, 14, 14, 64)\n",
    "L2 = tf.nn.conv2d(L1, filter=W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "#    Pool      ->(?, 7, 7, 64)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "L2 = tf.nn.dropout(L2, keep_prob=keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# L3 ImgIn shape=(?, 7, 7, 64)\n",
    "W3 = tf.Variable(tf.truncated_normal([3, 3, 64, 128], stddev=0.01))\n",
    "#    Conv      ->(?, 7, 7, 128)\n",
    "L3 = tf.nn.conv2d(L2, filter=W3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L3 = tf.nn.relu(L3)\n",
    "#    Pool      ->(?, 4, 4, 128)\n",
    "L3 = tf.nn.max_pool(L3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "L3 = tf.nn.dropout(L3, keep_prob=keep_prob)\n",
    "\n",
    "L3_flat = tf.reshape(L3, [-1, 128 * 4 * 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# L4 FC 4x4x128 inputs -> 625 outputs\n",
    "W4 = tf.get_variable(\"W4\", shape=[128 * 4 * 4, 625], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.truncated_normal([625], stddev=0.01))\n",
    "L4 = tf.nn.relu(tf.matmul(L3_flat, W4) + b4)\n",
    "L4 = tf.nn.dropout(L4, keep_prob=keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# L5 Final FC 625 inputs -> 10 outputs\n",
    "W5 = tf.get_variable(\"W5\", shape=[625, 10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.truncated_normal([10], stddev=0.01))\n",
    "logits = tf.matmul(L4, W5) + b5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning started. It takes sometime.\n",
      "Epoch: 0001 cost = 0.314817293\n",
      "Epoch: 0002 cost = 0.101358062\n",
      "Epoch: 0003 cost = 0.075268937\n",
      "Epoch: 0004 cost = 0.062139312\n",
      "Epoch: 0005 cost = 0.054043187\n",
      "Epoch: 0006 cost = 0.047333400\n",
      "Epoch: 0007 cost = 0.041649062\n",
      "Epoch: 0008 cost = 0.037869917\n",
      "Epoch: 0009 cost = 0.034863928\n",
      "Epoch: 0010 cost = 0.034775302\n",
      "Epoch: 0011 cost = 0.031832157\n",
      "Epoch: 0012 cost = 0.030607718\n",
      "Epoch: 0013 cost = 0.028367714\n",
      "Epoch: 0014 cost = 0.027992049\n",
      "Epoch: 0015 cost = 0.024209626\n",
      "Learning Finished!\n",
      "Accuracy: 0.9931\n",
      "Label:  [7]\n",
      "Prediction:  [7]\n"
     ]
    }
   ],
   "source": [
    "# start training\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    print('Learning started. It takes sometime.')\n",
    "    \n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            feed_dict = {X: batch_xs, Y: batch_ys, keep_prob: 0.7}\n",
    "            c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "            avg_cost += c / total_batch\n",
    "\n",
    "        print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "    print('Learning Finished!')\n",
    "    \n",
    "    # Test model and check accuracy\n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "          X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1}))\n",
    "\n",
    "    # Get one and predict\n",
    "    r = random.randint(0, mnist.test.num_examples - 1)\n",
    "    print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "    print(\"Prediction: \", sess.run(\n",
    "        tf.argmax(logits, 1), feed_dict={X: mnist.test.images[r:r + 1], keep_prob: 1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x233002b6c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist.test.images[r:r + 1].\n",
    "          reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
