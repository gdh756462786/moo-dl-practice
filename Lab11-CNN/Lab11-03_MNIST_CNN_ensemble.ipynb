{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../data/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"../data/MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 20\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the model to build\n",
    "class Model:\n",
    "    def __init__(self, sess, name):\n",
    "        self.sess = sess\n",
    "        self.name = name\n",
    "        self._build_net()\n",
    "        \n",
    "    def _build_net(self):\n",
    "        with tf.variable_scope(self.name):\n",
    "            # set training mode for dropout\n",
    "            self.is_training = tf.placeholder(tf.bool, name='is_trainig_mode')\n",
    "            \n",
    "            # input placeholders\n",
    "            self.X = tf.placeholder(tf.float32, [None, 784], name='X')\n",
    "            self.Y = tf.placeholder(tf.float32, [None, 10], name='Y')\n",
    "            X_img = tf.reshape(self.X, [-1, 28, 28, 1], name='X_img')\n",
    "            \n",
    "            # layer1: conv\n",
    "            L1 = tf.layers.conv2d(inputs=X_img, filters=32, kernel_size=[3, 3], padding='SAME', activation=tf.nn.relu)\n",
    "            L1 = tf.layers.max_pooling2d(inputs=L1, pool_size=[2, 2], padding='SAME', strides=2)\n",
    "            L1 = tf.layers.dropout(inputs=L1, rate=0.7, training=self.is_training)\n",
    "            \n",
    "            # layer2: conv\n",
    "            L2 = tf.layers.conv2d(inputs=L1, filters=64, kernel_size=[3, 3], padding='SAME', activation=tf.nn.relu)\n",
    "            L2 = tf.layers.max_pooling2d(inputs=L2, pool_size=[2, 2], padding='SAME', strides=2)\n",
    "            L2 = tf.layers.dropout(inputs=L2, rate=0.7, training=self.is_training)\n",
    "            \n",
    "            # layer3: conv\n",
    "            L3 = tf.layers.conv2d(inputs=L2, filters=128, kernel_size=[3, 3], padding='SAME', activation=tf.nn.relu)\n",
    "            L3 = tf.layers.max_pooling2d(inputs=L3, pool_size=[2, 2], padding='SAME', strides=2)\n",
    "            L3 = tf.layers.dropout(inputs=L3, rate=0.7, training=self.is_training)\n",
    "            \n",
    "            # layer4: fully connected\n",
    "            L3_flat = tf.reshape(L3, [-1, 128 * 4 * 4])\n",
    "            L4 = tf.layers.dense(inputs=L3_flat, units=625, activation=tf.nn.relu)\n",
    "            L4 = tf.layers.dropout(inputs=L4, rate=0.5, training=self.is_training)\n",
    "            \n",
    "            # final layer\n",
    "            self.logits = tf.layers.dense(inputs=L4, units=10)\n",
    "            \n",
    "        # cost & optimizer\n",
    "        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=self.logits, labels=self.Y))\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(self.cost)\n",
    "        \n",
    "        correct_prediction = tf.equal(tf.argmax(self.logits, 1), tf.argmax(self.Y, 1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        \n",
    "    def predict(self, x_test, training=False):\n",
    "        return self.sess.run(self.logits, feed_dict={self.X: x_test, self.is_training: training})\n",
    "    \n",
    "    def get_accuracy(self, x_test, y_test, training=True):\n",
    "        return self.sess.run(self.accuracy, feed_dict={self.X: x_test, self.Y: y_test, self.is_training: training})\n",
    "    \n",
    "    def train(self, x_data, y_data, training=True):\n",
    "        return self.sess.run([self.cost, self.optimizer], feed_dict={self.X: x_data, self.Y: y_data, self.is_training: training})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize session\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create multiple models\n",
    "models = []\n",
    "num_models = 10  # 2: 0.9914, 10: 0.9917\n",
    "for m in range(num_models):\n",
    "    models.append(Model(sess, 'model_' + str(m)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize variables\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Started!\n",
      "Epoch: 0001 cost = [ 0.80186316  0.77568675  0.74748487  0.79288081  0.77858696  0.79969638\n",
      "  0.74948728  0.75341648  0.7896797   0.78207075]\n",
      "Epoch: 0002 cost = [ 0.29005169  0.29451718  0.28792719  0.29716553  0.29229922  0.2920417\n",
      "  0.29104502  0.29045737  0.29815696  0.29127063]\n",
      "Epoch: 0003 cost = [ 0.22920355  0.2306721   0.22731929  0.23127657  0.2322948   0.23056679\n",
      "  0.23324648  0.23079267  0.23595522  0.22615084]\n",
      "Epoch: 0004 cost = [ 0.19608979  0.20363097  0.19841447  0.1987681   0.20396192  0.19982144\n",
      "  0.20148488  0.20222247  0.2062789   0.19780503]\n",
      "Epoch: 0005 cost = [ 0.18355306  0.18477394  0.18503631  0.18527276  0.18809424  0.1813539\n",
      "  0.18269716  0.18700593  0.18418929  0.18239645]\n",
      "Epoch: 0006 cost = [ 0.16616918  0.17209198  0.16483162  0.16927533  0.17742989  0.17249053\n",
      "  0.174654    0.17418641  0.17814687  0.16770007]\n",
      "Epoch: 0007 cost = [ 0.16406126  0.164169    0.16211505  0.15931919  0.16454028  0.16280193\n",
      "  0.15754638  0.16496893  0.16887667  0.16053149]\n",
      "Epoch: 0008 cost = [ 0.15719608  0.15892979  0.15449545  0.16007819  0.16200247  0.15481032\n",
      "  0.15326013  0.16047431  0.15932715  0.15254507]\n",
      "Epoch: 0009 cost = [ 0.14994384  0.15533671  0.15233312  0.15109242  0.15426522  0.14903111\n",
      "  0.14976555  0.15931566  0.15622604  0.14898913]\n",
      "Epoch: 0010 cost = [ 0.14810021  0.15040673  0.14768934  0.14880957  0.15314171  0.14628666\n",
      "  0.14381119  0.15295553  0.14847018  0.14524821]\n",
      "Epoch: 0011 cost = [ 0.1459775   0.14514473  0.14494139  0.14307529  0.1492899   0.13991854\n",
      "  0.1417605   0.1506139   0.14203891  0.1405217 ]\n",
      "Epoch: 0012 cost = [ 0.14135432  0.14396266  0.1403265   0.13665943  0.1408233   0.1430747\n",
      "  0.14122503  0.14888557  0.14586832  0.14218511]\n",
      "Epoch: 0013 cost = [ 0.13558643  0.1386606   0.13637534  0.14230622  0.1450884   0.13889097\n",
      "  0.13859436  0.14461992  0.14155736  0.13717905]\n",
      "Epoch: 0014 cost = [ 0.13981102  0.1402532   0.13939425  0.1340598   0.14107925  0.13420428\n",
      "  0.13846059  0.14146378  0.14009268  0.13466741]\n",
      "Epoch: 0015 cost = [ 0.13575258  0.13639213  0.13481648  0.13695412  0.13633744  0.13264759\n",
      "  0.13946904  0.13492197  0.13690625  0.1321638 ]\n",
      "Epoch: 0016 cost = [ 0.13053187  0.12996198  0.12896278  0.13436268  0.1358999   0.13123764\n",
      "  0.13658297  0.13956324  0.13346528  0.13292434]\n",
      "Epoch: 0017 cost = [ 0.13137561  0.1322317   0.1344211   0.13023391  0.13512226  0.13103879\n",
      "  0.12909326  0.13368968  0.13461356  0.1305186 ]\n",
      "Epoch: 0018 cost = [ 0.13065169  0.131166    0.12921607  0.13222789  0.13645909  0.13384132\n",
      "  0.13069453  0.13241285  0.1290355   0.12993862]\n",
      "Epoch: 0019 cost = [ 0.12811673  0.12886776  0.12819419  0.12585419  0.13728428  0.12861547\n",
      "  0.13248521  0.13054674  0.13191282  0.12637306]\n",
      "Epoch: 0020 cost = [ 0.12975465  0.12868836  0.12487336  0.12897517  0.13075443  0.12535766\n",
      "  0.126273    0.13238184  0.12763027  0.12375817]\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "print('Learning Started!')\n",
    "\n",
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost_list = np.zeros(len(models))\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "\n",
    "        # train each model\n",
    "        for m_idx, m in enumerate(models):\n",
    "            c, _ = m.train(batch_xs, batch_ys)\n",
    "            avg_cost_list[m_idx] += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', avg_cost_list)\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Accuracy: 0.9617\n",
      "1 Accuracy: 0.9563\n",
      "2 Accuracy: 0.9615\n",
      "3 Accuracy: 0.9652\n",
      "4 Accuracy: 0.9648\n",
      "5 Accuracy: 0.9641\n",
      "6 Accuracy: 0.9615\n",
      "7 Accuracy: 0.9617\n",
      "8 Accuracy: 0.9645\n",
      "9 Accuracy: 0.9621\n"
     ]
    }
   ],
   "source": [
    "# Test model and check accuracy\n",
    "test_size = len(mnist.test.labels)\n",
    "predictions = np.zeros(test_size * 10).reshape(test_size, 10)\n",
    "for m_idx, m in enumerate(models):\n",
    "    print(m_idx, 'Accuracy:', m.get_accuracy(\n",
    "        mnist.test.images, mnist.test.labels))\n",
    "    p = m.predict(mnist.test.images)\n",
    "    \n",
    "    # sum all predictions from each model(prediction is softmax output)\n",
    "    predictions += p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble accuracy: 0.9917\n"
     ]
    }
   ],
   "source": [
    "ensemble_correct_prediction = tf.equal(tf.argmax(predictions, 1), tf.argmax(mnist.test.labels, 1))\n",
    "ensemble_accuracy = tf.reduce_mean(tf.cast(ensemble_correct_prediction, tf.float32))\n",
    "print('Ensemble accuracy:', sess.run(ensemble_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
