{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../data/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"../data/MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reshape needed for CNN\n",
    "# gray image(1-channel) with size 28 x 28\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# L1 ImgIn shape=(?, 28, 28, 1)\n",
    "W1 = tf.Variable(tf.truncated_normal([3, 3, 1, 32], stddev=0.01))\n",
    "#    Conv     -> (?, 28, 28, 32)\n",
    "L1 = tf.nn.conv2d(X_img, filter=W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L1 = tf.nn.relu(L1)\n",
    "#    Pool     -> (?, 14, 14, 32)\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# L2 ImgIn shape=(?, 14, 14, 32)\n",
    "W2 = tf.Variable(tf.truncated_normal([3, 3, 32, 64], stddev=0.01))\n",
    "#    Conv      ->(?, 14, 14, 64)\n",
    "L2 = tf.nn.conv2d(L1, filter=W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "#    Pool      ->(?, 7, 7, 64)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "L2_flat = tf.reshape(L2, [-1, 7 * 7 * 64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final FC 7x7x64 inputs -> 10 outputs\n",
    "W3 = tf.get_variable('W3', shape=[7 * 7 * 64, 10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b = tf.Variable(tf.truncated_normal([10], stddev=0.01))\n",
    "logits = tf.matmul(L2_flat, W3) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning started. It takes sometime.\n",
      "Epoch: 0001 cost = 0.300673964\n",
      "Epoch: 0002 cost = 0.094394681\n",
      "Epoch: 0003 cost = 0.070280382\n",
      "Epoch: 0004 cost = 0.055861046\n",
      "Epoch: 0005 cost = 0.049839804\n",
      "Epoch: 0006 cost = 0.041798953\n",
      "Epoch: 0007 cost = 0.036628591\n",
      "Epoch: 0008 cost = 0.032806194\n",
      "Epoch: 0009 cost = 0.029222660\n",
      "Epoch: 0010 cost = 0.025962060\n",
      "Epoch: 0011 cost = 0.022046790\n",
      "Epoch: 0012 cost = 0.020609769\n",
      "Epoch: 0013 cost = 0.017342991\n",
      "Epoch: 0014 cost = 0.015640816\n",
      "Epoch: 0015 cost = 0.013368904\n",
      "Learning Finished!\n",
      "Accuracy: 0.988\n",
      "Label:  [3]\n",
      "Prediction:  [3]\n"
     ]
    }
   ],
   "source": [
    "# start training\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    print('Learning started. It takes sometime.')\n",
    "    \n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            feed_dict = {X: batch_xs, Y: batch_ys}\n",
    "            c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "            avg_cost += c / total_batch\n",
    "\n",
    "        print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "    print('Learning Finished!')\n",
    "    \n",
    "    # Test model and check accuracy\n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "          X: mnist.test.images, Y: mnist.test.labels}))\n",
    "\n",
    "    # Get one and predict\n",
    "    r = random.randint(0, mnist.test.num_examples - 1)\n",
    "    print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "    print(\"Prediction: \", sess.run(\n",
    "        tf.argmax(logits, 1), feed_dict={X: mnist.test.images[r:r + 1]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21795905898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist.test.images[r:r + 1].\n",
    "          reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
