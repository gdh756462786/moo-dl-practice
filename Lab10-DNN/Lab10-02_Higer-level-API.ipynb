{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import random\n",
    "tf.set_random_seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"../data/MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature & class dimensions\n",
    "n_features = 28 * 28\n",
    "hidden_output_size = 512 # layer output size\n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, n_features])\n",
    "Y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob = 0.7\n",
    "learning_rate = tf.placeholder(tf.float32, name='learning_rate')\n",
    "train_mode = tf.placeholder(tf.bool, name='train_mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xavier_init = tf.contrib.layers.xavier_initializer()\n",
    "bn_params = {\n",
    "    'is_training': train_mode,\n",
    "    'decay': 0.9,\n",
    "    'updates_collections': None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can build short code using 'arg_scope' to avoid duplicate code\n",
    "# same function with different arguments\n",
    "with tf.contrib.framework.arg_scope([tf.contrib.layers.fully_connected],\n",
    "                                    activation_fn=tf.nn.relu,\n",
    "                                    weights_initializer=xavier_init,\n",
    "                                    biases_initializer=None,\n",
    "                                    normalizer_fn=tf.contrib.layers.batch_norm,\n",
    "                                    normalizer_params=bn_params):\n",
    "    hidden_layer1 = tf.contrib.layers.fully_connected(X, hidden_output_size, scope='h1')\n",
    "    h1_drop = tf.contrib.layers.dropout(hidden_layer1, keep_prob, is_training=train_mode)\n",
    "    \n",
    "    hidden_layer2 = tf.contrib.layers.fully_connected(h1_drop, hidden_output_size, scope='h2')\n",
    "    h2_drop = tf.contrib.layers.dropout(hidden_layer2, keep_prob, is_training=train_mode)\n",
    "    \n",
    "    hidden_layer3 = tf.contrib.layers.fully_connected(h2_drop, hidden_output_size, scope='h3')\n",
    "    h3_drop = tf.contrib.layers.dropout(hidden_layer3, keep_prob, is_training=train_mode)\n",
    "    \n",
    "    hidden_layer4 = tf.contrib.layers.fully_connected(h3_drop, hidden_output_size, scope='h4')\n",
    "    h4_drop = tf.contrib.layers.dropout(hidden_layer4, keep_prob, is_training=train_mode)\n",
    "    \n",
    "    hypothesis = tf.contrib.layers.fully_connected(h4_drop, n_classes, activation_fn=None, scope='hypothesis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "lr = 0.01 # learning_rate\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:    1] cost = 0.379521402\n",
      "[Epoch:    2] cost = 0.322382897\n",
      "[Epoch:    3] cost = 0.312713024\n",
      "[Epoch:    4] cost = 0.305946242\n",
      "[Epoch:    5] cost = 0.30204906\n",
      "[Epoch:    6] cost = 0.298805944\n",
      "[Epoch:    7] cost = 0.297290141\n",
      "[Epoch:    8] cost = 0.296245888\n",
      "[Epoch:    9] cost = 0.294301923\n",
      "[Epoch:   10] cost = 0.292638078\n",
      "[Epoch:   11] cost = 0.293517785\n",
      "[Epoch:   12] cost = 0.291447719\n",
      "[Epoch:   13] cost = 0.291446638\n",
      "[Epoch:   14] cost = 0.290904016\n",
      "[Epoch:   15] cost = 0.289642102\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict_train = {X: batch_xs, Y: batch_ys, train_mode: True, learning_rate: lr}\n",
    "        feed_dict_cost = {X: batch_xs, Y: batch_ys, train_mode: False, learning_rate: lr}\n",
    "        opt = sess.run(optimizer, feed_dict=feed_dict_train)\n",
    "        c = sess.run(cost, feed_dict=feed_dict_cost)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print(\"[Epoch: {:>4}] cost = {:>.9}\".format(epoch + 1, avg_cost))\n",
    "    #print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.985\n"
     ]
    }
   ],
   "source": [
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels, train_mode: False}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  [8]\n",
      "Prediction:  [8]\n"
     ]
    }
   ],
   "source": [
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r + 1], train_mode: False}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTOKjzgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20306729160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist.test.images[r:r + 1].\n",
    "          reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
