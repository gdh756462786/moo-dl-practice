{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare packages\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get data sets\n",
    "import os\n",
    "from glob import glob\n",
    "import helper\n",
    "dataset_dir = '../Data_sets/'\n",
    "test_images = helper.get_batch(glob(os.path.join(dataset_dir, 'img_align_celeba/*.jpg'))[:25], 64, 64, 'RGB')\n",
    "plt.imshow(helper.images_square_grid(test_images, 'RGB'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "celebA_dataset = helper.Dataset(glob(os.path.join(dataset_dir, 'img_align_celeba/*.jpg')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# display function\n",
    "def show_generator_output(sess, n_images, input_z, out_channel_dim, image_mode):\n",
    "    \"\"\"\n",
    "    Show example output for the generator\n",
    "    :param sess: TensorFlow session\n",
    "    :param n_images: Number of Images to display\n",
    "    :param input_z: Input Z Tensor\n",
    "    :param out_channel_dim: The number of channels in the output image\n",
    "    :param image_mode: The mode to use for images (\"RGB\" or \"L\")\n",
    "    \"\"\"\n",
    "    cmap = None if image_mode == 'RGB' else 'gray'\n",
    "    z_dim = input_z.get_shape().as_list()[-1]\n",
    "    example_z = np.random.uniform(-1, 1, size=[n_images, z_dim])\n",
    "    \n",
    "    samples = sess.run(\n",
    "        generator(input_z, out_channel_dim, reuse=True, is_training=False),\n",
    "        feed_dict={input_z: example_z})\n",
    "    \n",
    "    images_grid = helper.images_square_grid(samples, image_mode)\n",
    "    plt.imshow(images_grid, cmap=cmap)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input placeholders\n",
    "def model_inputs(image_width, image_height, image_channels, z_dim):\n",
    "    inputs_real = tf.placeholder(tf.float32, [None, image_width, image_height, image_channels], name='input_real')\n",
    "    inputs_z = tf.placeholder(tf.float32, [None, z_dim], name='input_z')\n",
    "    \n",
    "    return inputs_real, inputs_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(z, output_dim, reuse=False, initial_feature_size=1024, alpha=0.2, is_training=True):\n",
    "    with tf.variable_scope('generator', reuse=reuse):        \n",
    "        # try different weight initializer\n",
    "        # w_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "        # w_init = tf.truncated_normal_initializer(stddev=0.02)\n",
    "        w_init = tf.contrib.layers.xavier_initializer()\n",
    "        \n",
    "        # 1. Fully connected layer (make 4x4x512) & reshape to prepare first layer\n",
    "        feature_map_size = initial_feature_size\n",
    "        x1 = tf.layers.dense(inputs=z, \n",
    "                             units=4*4*feature_map_size, \n",
    "                             activation=None, \n",
    "                             use_bias=True, \n",
    "                             kernel_initializer=w_init)\n",
    "        x1 = tf.reshape(tensor=x1, shape=[-1, 4, 4, feature_map_size])\n",
    "        x1 = tf.layers.batch_normalization(inputs=x1, training=is_training)\n",
    "        x1 = tf.maximum(alpha * x1, x1)\n",
    "        \n",
    "        # 2. deconvolutional layer (make 8x8x256)\n",
    "        feature_map_size = feature_map_size // 2\n",
    "        x2 = tf.layers.conv2d_transpose(inputs=x1, \n",
    "                                        filters=feature_map_size, \n",
    "                                        kernel_size=5, \n",
    "                                        strides=2, \n",
    "                                        padding='same', \n",
    "                                        activation=None, \n",
    "                                        kernel_initializer=w_init)\n",
    "        x2 = tf.layers.batch_normalization(inputs=x2, training=is_training)\n",
    "        x2 = tf.maximum(alpha * x2, x2)\n",
    "        \n",
    "        # 3. deconvolutional layer (make 16x16x128)\n",
    "        feature_map_size = feature_map_size // 2\n",
    "        x3 = tf.layers.conv2d_transpose(inputs=x2, \n",
    "                                        filters=feature_map_size, \n",
    "                                        kernel_size=5, \n",
    "                                        strides=2, \n",
    "                                        padding='same', \n",
    "                                        activation=None, \n",
    "                                        kernel_initializer=w_init)\n",
    "        x3 = tf.layers.batch_normalization(inputs=x3, training=is_training)\n",
    "        x3 = tf.maximum(alpha * x3, x3)\n",
    "        \n",
    "        # 4. deconvolutional layer (make 32x32x64)\n",
    "        feature_map_size = feature_map_size // 2\n",
    "        x4 = tf.layers.conv2d_transpose(inputs=x3, \n",
    "                                        filters=feature_map_size, \n",
    "                                        kernel_size=5, \n",
    "                                        strides=2, \n",
    "                                        padding='same', \n",
    "                                        activation=None, \n",
    "                                        kernel_initializer=w_init)\n",
    "        x4 = tf.layers.batch_normalization(inputs=x4, training=is_training)\n",
    "        x4 = tf.maximum(alpha * x4, x4)\n",
    "        \n",
    "        # 4. Output layer, 64x64x3\n",
    "        logits = tf.layers.conv2d_transpose(inputs=x4, \n",
    "                                            filters=output_dim, \n",
    "                                            kernel_size=5, \n",
    "                                            strides=2, \n",
    "                                            padding='same', \n",
    "                                            activation=None,\n",
    "                                            kernel_initializer=w_init)\n",
    "        out = tf.tanh(logits)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator(x, reuse=False, initial_filter_size=64, alpha=0.2, is_training=True):\n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        # input is 64x64x3\n",
    "        \n",
    "        # try different weight initializer\n",
    "        # w_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "        # w_init = tf.truncated_normal_initializer(stddev=0.02)\n",
    "        w_init = tf.contrib.layers.xavier_initializer()\n",
    "        \n",
    "        # 1. make 32x32x64\n",
    "        filters = initial_filter_size\n",
    "        x1 = tf.layers.conv2d(inputs=x, \n",
    "                              filters=filters, \n",
    "                              kernel_size=5, \n",
    "                              strides=2, \n",
    "                              padding='same', \n",
    "                              activation=None, \n",
    "                              kernel_initializer=w_init)\n",
    "        x1 = tf.maximum(alpha * x1, x1)\n",
    "        \n",
    "        # 2. make 16x16x128\n",
    "        filters = filters * 2\n",
    "        x2 = tf.layers.conv2d(inputs=x1, \n",
    "                              filters=filters, \n",
    "                              kernel_size=5, \n",
    "                              strides=2, \n",
    "                              padding='same', \n",
    "                              activation=None, \n",
    "                              kernel_initializer=w_init)\n",
    "        x2 = tf.layers.batch_normalization(inputs=x2, training=True)\n",
    "        x2 = tf.maximum(alpha * x2, x2)\n",
    "        \n",
    "        # 3. make 8x8x256\n",
    "        filters = filters * 2\n",
    "        x3 = tf.layers.conv2d(inputs=x2, \n",
    "                              filters=filters, \n",
    "                              kernel_size=5, \n",
    "                              strides=2, \n",
    "                              padding='same', \n",
    "                              activation=None, \n",
    "                              kernel_initializer=w_init)\n",
    "        x3 = tf.layers.batch_normalization(inputs=x3, training=True)\n",
    "        x3 = tf.maximum(alpha * x3, x3)\n",
    "        \n",
    "        # 4. make 4x4x512\n",
    "        filters = filters * 2\n",
    "        x4 = tf.layers.conv2d(inputs=x3, \n",
    "                              filters=filters, \n",
    "                              kernel_size=5, \n",
    "                              strides=2, \n",
    "                              padding='same', \n",
    "                              activation=None, \n",
    "                              kernel_initializer=w_init)\n",
    "        x4 = tf.layers.batch_normalization(inputs=x4, training=True)\n",
    "        x4 = tf.maximum(alpha * x4, x4)\n",
    "        \n",
    "        # 5. flatten the layer\n",
    "        flattend_layer = tf.reshape(tensor=x4, shape=[-1, 4*4*filters])\n",
    "        logits = tf.layers.dense(inputs=flattend_layer, \n",
    "                                 units=1, \n",
    "                                 activation=None, \n",
    "                                 use_bias=True, \n",
    "                                 kernel_initializer=w_init)\n",
    "        out = tf.sigmoid(logits)\n",
    "    return out, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_loss(input_real, input_z, output_dim, alpha=0.2, smooth=0.1):\n",
    "    \"\"\"\n",
    "    Get the loss for the discriminator and generator\n",
    "    :param input_real: Images from the real dataset\n",
    "    :param input_z: Z input\n",
    "    :param out_channel_dim: The number of channels in the output image\n",
    "    :return: A tuple of (discriminator loss, generator loss)\n",
    "    \"\"\"\n",
    "    g_model = generator(input_z, output_dim, alpha=alpha)\n",
    "    d_model_real, d_logits_real = discriminator(input_real, alpha=alpha)\n",
    "    d_model_fake, d_logits_fake = discriminator(g_model, reuse=True, alpha=alpha)\n",
    "    \n",
    "    d_real_label = tf.ones_like(d_logits_real) * (1 - smooth)\n",
    "    d_fake_label = tf.zeros_like(d_logits_real)\n",
    "    d_loss_real = tf.reduce_mean( tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_real, labels=d_real_label) )\n",
    "    d_loss_fake = tf.reduce_mean( tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake, labels=d_fake_label) )\n",
    "    g_loss = tf.reduce_mean( tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake, labels=tf.ones_like(d_model_fake)) )\n",
    "\n",
    "    d_loss = d_loss_real + d_loss_fake\n",
    "\n",
    "    return d_loss, g_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_opt(d_loss, g_loss, learning_rate, beta1):\n",
    "    \"\"\"\n",
    "    Get optimization operations\n",
    "    :param d_loss: Discriminator loss Tensor\n",
    "    :param g_loss: Generator loss Tensor\n",
    "    :param learning_rate: Learning Rate Placeholder\n",
    "    :param beta1: The exponential decay rate for the 1st moment in the optimizer\n",
    "    :return: A tuple of (discriminator training operation, generator training operation)\n",
    "    \"\"\"\n",
    "    # Get weights and bias to update\n",
    "    t_vars = tf.trainable_variables()\n",
    "    d_vars = [var for var in t_vars if var.name.startswith('discriminator')]\n",
    "    g_vars = [var for var in t_vars if var.name.startswith('generator')]\n",
    "\n",
    "    # Optimize\n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "        d_train_opt = tf.train.AdamOptimizer(learning_rate, beta1=beta1).minimize(d_loss, var_list=d_vars)\n",
    "        g_train_opt = tf.train.AdamOptimizer(learning_rate, beta1=beta1).minimize(g_loss, var_list=g_vars)\n",
    "\n",
    "    return d_train_opt, g_train_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DCGAN:\n",
    "    def __init__(self, data_shape, z_size, learning_rate, alpha=0.2, beta1=0.5, smooth=0.1):\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        self.input_real, self.input_z = model_inputs(data_shape[1], data_shape[2], data_shape[3], z_size)\n",
    "        \n",
    "        self.d_loss, self.g_loss = model_loss(self.input_real, self.input_z, data_shape[3], alpha=alpha, smooth=smooth)\n",
    "        \n",
    "        self.d_opt, self.g_opt = model_opt(self.d_loss, self.g_loss, learning_rate, beta1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(net, epochs, batch_size, get_batches, data_shape, data_image_mode, show_n_images, print_every=10, show_every=100):\n",
    "    losses = []\n",
    "    steps = 0\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for e in range(epochs):\n",
    "            for batch_images in get_batches(batch_size):\n",
    "                steps += 1\n",
    "                \n",
    "                # Sample random noise for G\n",
    "                batch_z = np.random.uniform(-1, 1, size=(batch_size, z_size))\n",
    "\n",
    "                # Run optimizers\n",
    "                _ = sess.run(net.d_opt, feed_dict={net.input_real: batch_images, net.input_z: batch_z})\n",
    "                _ = sess.run(net.g_opt, feed_dict={net.input_z: batch_z, net.input_real: batch_images})\n",
    "\n",
    "                if steps % print_every == 0:\n",
    "                    # At the end of each epoch, get the losses and print them out\n",
    "                    train_loss_d = net.d_loss.eval({net.input_z: batch_z, net.input_real: batch_images})\n",
    "                    train_loss_g = net.g_loss.eval({net.input_z: batch_z})\n",
    "\n",
    "                    print(\"Epoch {}/{}...\".format(e+1, epochs),\n",
    "                          \"Discriminator Loss: {:.4f}...\".format(train_loss_d),\n",
    "                          \"Generator Loss: {:.4f}\".format(train_loss_g))\n",
    "                    # Save losses to view after training\n",
    "                    losses.append((train_loss_d, train_loss_g))\n",
    "\n",
    "                if steps % show_every == 0:        \n",
    "                    show_generator_output(sess, show_n_images, net.input_z, data_shape[3], data_image_mode)\n",
    "                    \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_size = 256\n",
    "learning_rate = 0.0002\n",
    "batch_size = 128\n",
    "epochs = 2\n",
    "alpha = 0.2\n",
    "beta1 = 0.5\n",
    "smooth = 0.1\n",
    "show_n_images = 25\n",
    "\n",
    "# Create the network\n",
    "net = DCGAN(celebA_dataset.shape, z_size, learning_rate, alpha=alpha, beta1=beta1, smooth=smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = train(net, epochs, batch_size, celebA_dataset.get_batches, celebA_dataset.shape, celebA_dataset.image_mode, show_n_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "losses = np.array(losses)\n",
    "plt.plot(losses.T[0], label='Discriminator', alpha=0.5)\n",
    "plt.plot(losses.T[1], label='Generator', alpha=0.5)\n",
    "plt.title(\"Training Losses\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
