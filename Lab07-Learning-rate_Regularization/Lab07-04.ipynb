{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lab 7 Learning rate and Evaluation\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "tf.set_random_seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# grab mnist dataset\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('../data/MNIST_data/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MNIST data image of shape 28 * 28 = 784\n",
    "n_features = 28 * 28\n",
    "# there are 10 digits 0 ~ 9\n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MNIST data image of shape 28 * 28 = 784\n",
    "X = tf.placeholder(tf.float32, [None, n_features])\n",
    "# 0 - 9 digits recognition = 10 classes\n",
    "Y = tf.placeholder(tf.float32, [None, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# variables\n",
    "W = tf.Variable(tf.random_normal([n_features, n_classes]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([n_classes]), name='bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hypoethesis\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loss\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# optimizer\n",
    "learning_rate = tf.placeholder(tf.float32, name='learning_rate')\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "is_correct = tf.equal(tf.arg_max(hypothesis, 1), tf.arg_max(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "lr = 0.1\n",
    "training_epochs = 100\n",
    "batch_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 4.114214563\n",
      "Epoch: 0002 cost = 1.530929253\n",
      "Epoch: 0003 cost = 1.142260440\n",
      "Epoch: 0004 cost = 0.968999422\n",
      "Epoch: 0005 cost = 0.867736959\n",
      "Epoch: 0006 cost = 0.798704204\n",
      "Epoch: 0007 cost = 0.749200316\n",
      "Epoch: 0008 cost = 0.710646632\n",
      "Epoch: 0009 cost = 0.679439394\n",
      "Epoch: 0010 cost = 0.653367372\n",
      "Epoch: 0011 cost = 0.630692393\n",
      "Epoch: 0012 cost = 0.611935920\n",
      "Epoch: 0013 cost = 0.595007852\n",
      "Epoch: 0014 cost = 0.580045041\n",
      "Epoch: 0015 cost = 0.566693564\n",
      "Epoch: 0016 cost = 0.554400768\n",
      "Epoch: 0017 cost = 0.543420343\n",
      "Epoch: 0018 cost = 0.533369329\n",
      "Epoch: 0019 cost = 0.523987991\n",
      "Epoch: 0020 cost = 0.515117663\n",
      "Epoch: 0021 cost = 0.507399438\n",
      "Epoch: 0022 cost = 0.499618605\n",
      "Epoch: 0023 cost = 0.492880769\n",
      "Epoch: 0024 cost = 0.486258377\n",
      "Epoch: 0025 cost = 0.480087358\n",
      "Epoch: 0026 cost = 0.474147913\n",
      "Epoch: 0027 cost = 0.468765296\n",
      "Epoch: 0028 cost = 0.463664472\n",
      "Epoch: 0029 cost = 0.458645085\n",
      "Epoch: 0030 cost = 0.453943294\n",
      "Epoch: 0031 cost = 0.449531507\n",
      "Epoch: 0032 cost = 0.445108889\n",
      "Epoch: 0033 cost = 0.440860214\n",
      "Epoch: 0034 cost = 0.437028709\n",
      "Epoch: 0035 cost = 0.432957385\n",
      "Epoch: 0036 cost = 0.429664814\n",
      "Epoch: 0037 cost = 0.426066932\n",
      "Epoch: 0038 cost = 0.422582003\n",
      "Epoch: 0039 cost = 0.419630843\n",
      "Epoch: 0040 cost = 0.416382711\n",
      "Epoch: 0041 cost = 0.413253193\n",
      "Epoch: 0042 cost = 0.410375581\n",
      "Epoch: 0043 cost = 0.407605734\n",
      "Epoch: 0044 cost = 0.404830273\n",
      "Epoch: 0045 cost = 0.402291590\n",
      "Epoch: 0046 cost = 0.399722639\n",
      "Epoch: 0047 cost = 0.397226365\n",
      "Epoch: 0048 cost = 0.394740156\n",
      "Epoch: 0049 cost = 0.392470515\n",
      "Epoch: 0050 cost = 0.390197426\n",
      "Epoch: 0051 cost = 0.387934774\n",
      "Epoch: 0052 cost = 0.385833542\n",
      "Epoch: 0053 cost = 0.383584944\n",
      "Epoch: 0054 cost = 0.381781152\n",
      "Epoch: 0055 cost = 0.379746760\n",
      "Epoch: 0056 cost = 0.377760574\n",
      "Epoch: 0057 cost = 0.375968689\n",
      "Epoch: 0058 cost = 0.374358087\n",
      "Epoch: 0059 cost = 0.372353574\n",
      "Epoch: 0060 cost = 0.370568578\n",
      "Epoch: 0061 cost = 0.368817591\n",
      "Epoch: 0062 cost = 0.367268972\n",
      "Epoch: 0063 cost = 0.365571641\n",
      "Epoch: 0064 cost = 0.363847731\n",
      "Epoch: 0065 cost = 0.362392292\n",
      "Epoch: 0066 cost = 0.360808321\n",
      "Epoch: 0067 cost = 0.359428016\n",
      "Epoch: 0068 cost = 0.357943840\n",
      "Epoch: 0069 cost = 0.356575916\n",
      "Epoch: 0070 cost = 0.355028485\n",
      "Epoch: 0071 cost = 0.353697760\n",
      "Epoch: 0072 cost = 0.352421926\n",
      "Epoch: 0073 cost = 0.351033314\n",
      "Epoch: 0074 cost = 0.349783633\n",
      "Epoch: 0075 cost = 0.348508667\n",
      "Epoch: 0076 cost = 0.347334528\n",
      "Epoch: 0077 cost = 0.346013810\n",
      "Epoch: 0078 cost = 0.345136387\n",
      "Epoch: 0079 cost = 0.343633044\n",
      "Epoch: 0080 cost = 0.342523905\n",
      "Epoch: 0081 cost = 0.341416036\n",
      "Epoch: 0082 cost = 0.340417152\n",
      "Epoch: 0083 cost = 0.339203781\n",
      "Epoch: 0084 cost = 0.338170797\n",
      "Epoch: 0085 cost = 0.337116547\n",
      "Epoch: 0086 cost = 0.336312012\n",
      "Epoch: 0087 cost = 0.335066050\n",
      "Epoch: 0088 cost = 0.334229094\n",
      "Epoch: 0089 cost = 0.333050419\n",
      "Epoch: 0090 cost = 0.332191993\n",
      "Epoch: 0091 cost = 0.331314390\n",
      "Epoch: 0092 cost = 0.330435208\n",
      "Epoch: 0093 cost = 0.329271455\n",
      "Epoch: 0094 cost = 0.328485410\n",
      "Epoch: 0095 cost = 0.327600129\n",
      "Epoch: 0096 cost = 0.326727314\n",
      "Epoch: 0097 cost = 0.325864170\n",
      "Epoch: 0098 cost = 0.324966249\n",
      "Epoch: 0099 cost = 0.324099711\n",
      "Epoch: 0100 cost = 0.323360618\n",
      "Learning finished\n",
      "Accuracy:  0.9113\n",
      "Label:  [1]\n",
      "Prediction:  [1]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x179800ae208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # initialize \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # training\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            c, _ = sess.run([cost, optimizer], feed_dict={X: batch_xs, Y: batch_ys, learning_rate: lr})\n",
    "            avg_cost += c / total_batch\n",
    "\n",
    "        print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "    print(\"Learning finished\")\n",
    "\n",
    "    # Test the model using test sets\n",
    "    print(\"Accuracy: \", accuracy.eval(session=sess, feed_dict={X: mnist.test.images, Y: mnist.test.labels}))\n",
    "\n",
    "    # Get one and predict\n",
    "    r = random.randint(0, mnist.test.num_examples - 1)\n",
    "    print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "    print(\"Prediction: \", sess.run(tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r + 1]}))\n",
    "\n",
    "    plt.imshow(\n",
    "        mnist.test.images[r:r + 1].reshape(28, 28),\n",
    "        cmap='Greys',\n",
    "        interpolation='nearest')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
